# Visual-Aid-For-Blind


This project makes the blind aware about the surroundings using image captioning and object    detection. It generates the caption for it with the help of Deep Learning (Neural Network) and converts the generated caption into voice using text to voice API.

Visually impaired people have to face many challenges in day to day life like recognizing objects in the surroundings. They cannot always rely on other people to describe the surroundings. This project aims to provide self dependency to blind persons upto some extent using image captioning and object detection.

Firstly, I installed the suitable libraries/modules in our jupyter notebook and then I found the suitable dataset (which is on the COCO website) for my model.
This model basically consists of 2 different inputs, one for images and other for captions. Hence there will be two outputs for the above two inputs.
